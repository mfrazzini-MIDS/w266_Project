{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W266 Final Project - Feature_Sentence_Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mfrazzini/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package brown to /home/mfrazzini/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mfrazzini/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mfrazzini/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Import a bunch of libraries.\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "from IPython.core.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import brown\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import webtext\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070247, 4)\n",
      "Unnamed: 0                     0\n",
      "SENTENCE_ID                    0\n",
      "SENTENCE          Great suitcase\n",
      "TESTIMONIAL_ID           1369284\n",
      "Name: 0, dtype: object\n",
      "Unnamed: 0                                                        1\n",
      "SENTENCE_ID                                                       1\n",
      "SENTENCE          I am no longer afraid of my stuff being squash...\n",
      "TESTIMONIAL_ID                                              1369284\n",
      "Name: 1, dtype: object\n",
      "(212887, 3)\n",
      "MODELID                              9863\n",
      "FEATUREID                            3387\n",
      "FEATURENAME    Removable checkbook holder\n",
      "Name: 0, dtype: object\n",
      "MODELID                    9863\n",
      "FEATUREID                  3388\n",
      "FEATURENAME    Bill compartment\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Dev:\n",
    "#review_sentences = pd.read_csv('../data/Review_sentences_Dev_Active_Cleansed_2018-07-09.csv')\n",
    "#Prod:\n",
    "review_sentences = pd.read_csv('../data/Review_sentences_Prod_Active_Cleansed_2018-07-09.csv')\n",
    "\n",
    "print(review_sentences.shape)\n",
    "print(review_sentences.loc[0])\n",
    "print(review_sentences.loc[1])\n",
    "features = pd.read_csv('../data/FeatureDump_All_Active_2018-07-09T16_31_17.csv')\n",
    "print(features.shape)\n",
    "print(features.loc[0])\n",
    "print(features.loc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 167164 instances, test on 55722 instances\n",
      "accuracy: 0.9609310505724848\n",
      "Most Informative Features\n",
      "              girlfriend = True              neu : sub    =   1031.1 : 1.0\n",
      "                 decides = True              neu : sub    =    845.2 : 1.0\n",
      "               detective = True              neu : sub    =    827.7 : 1.0\n",
      "                 married = True              neu : sub    =    769.7 : 1.0\n",
      "                daughter = True              neu : sub    =    692.2 : 1.0\n",
      "               boyfriend = True              neu : sub    =    653.5 : 1.0\n",
      "                    kill = True              neu : sub    =    618.6 : 1.0\n",
      "                    nick = True              neu : sub    =    566.4 : 1.0\n",
      "                  leader = True              neu : sub    =    508.3 : 1.0\n",
      "                   plans = True              neu : sub    =    479.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    " \n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "#Load subjective lines into a list\n",
    "s = open(r'../data/quote.tok.gt9.5000', encoding = \"ISO-8859-1\")\n",
    "subtxt = s.readlines()\n",
    "#Append with actual bag feature list to dramatically improve accuracy\n",
    "for index, row in features.iterrows():\n",
    "    if type(row['FEATURENAME']) is str:\n",
    "        subtxt.append(row['FEATURENAME'])\n",
    " \n",
    "\n",
    "#Load neutral lines into a list\n",
    "n = open(r'../data/plot.tok.gt9.5000', encoding = \"ISO-8859-1\")\n",
    "neutxt = n.readlines()\n",
    "\n",
    "\n",
    "subfeats = [(word_feats(nltk.word_tokenize(subtxt[x])), 'sub') for x in range(0,len(subtxt))]\n",
    "neufeats = [(word_feats(nltk.word_tokenize(neutxt[x])), 'neu') for x in range(0,len(neutxt))]\n",
    " \n",
    "subcutoff = int(len(subfeats)*3/4)\n",
    "neucutoff = int(len(neufeats)*3/4)\n",
    " \n",
    "trainfeats = subfeats[:subcutoff] + neufeats[:neucutoff]\n",
    "testfeats = subfeats[subcutoff:] + neufeats[neucutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats)))\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(trainfeats)\n",
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testfeats))\n",
    "classifier.show_most_informative_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 1070247 Subjective: 333050 Neutral: 736136\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Feature_sentences_Prod_Active_2018-07-09.csv','w') as csvfile:\n",
    "    fieldnames=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE']\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(fieldnames)\n",
    "\n",
    "with open('NotFeature_sentences_Prod_Active_2018-07-09.csv','w') as csvfile2:\n",
    "    fieldnames=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE']\n",
    "    writer=csv.writer(csvfile2)\n",
    "    writer.writerow(fieldnames)\n",
    "\n",
    "sentences = 0\n",
    "subjective = 0\n",
    "neutral = 0\n",
    "feature_sentences = pd.DataFrame()\n",
    "not_feature_sentences = pd.DataFrame()\n",
    "for index, row in review_sentences.iterrows():\n",
    "    sentences += 1\n",
    "    if type(row['SENTENCE']) is str:\n",
    "        if (classifier.prob_classify(word_feats(nltk.word_tokenize(row['SENTENCE']))).prob('sub')) > .9:\n",
    "            subjective += 1\n",
    "            #print(row['SENTENCE'])\n",
    "            feature_sentences = pd.DataFrame(columns=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE'])\n",
    "            feature_sentences.loc[0,'TESTIMONIAL_ID'] = row['TESTIMONIAL_ID']\n",
    "            feature_sentences.loc[0,'SENTENCE_ID'] = row['SENTENCE_ID']\n",
    "            feature_sentences.loc[0,'SENTENCE'] = row['SENTENCE']\n",
    "            feature_sentences.to_csv(\"Feature_sentences_Prod_Active_2018-07-09.csv\",mode='a', header=False, index=False)\n",
    "        else:\n",
    "            neutral += 1\n",
    "            not_feature_sentences = pd.DataFrame(columns=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE'])\n",
    "            not_feature_sentences.loc[0,'TESTIMONIAL_ID'] = row['TESTIMONIAL_ID']\n",
    "            not_feature_sentences.loc[0,'SENTENCE_ID'] = row['SENTENCE_ID']\n",
    "            not_feature_sentences.loc[0,'SENTENCE'] = row['SENTENCE']\n",
    "            not_feature_sentences.to_csv(\"NotFeature_sentences_Prod_Active_2018-07-09.csv\",mode='a', header=False, index=False)\n",
    "            \n",
    "print(\"Sentences:\", sentences, \"Subjective:\", subjective, \"Neutral:\", neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Removable', 'JJ'), ('checkbook', 'NN'), ('holder', 'NN')]\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "feature_text = word_tokenize(features.loc[0]['FEATURENAME'])\n",
    "tagged_text = nltk.pos_tag(feature_text)\n",
    "print(tagged_text)\n",
    "print(feature_sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 333050 Pattern Match: 146018 No Pattern Match: 187032\n"
     ]
    }
   ],
   "source": [
    "with open('Feature_sentences_Prod_Final_2018-07-09.csv','w') as csvfile:\n",
    "    fieldnames=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE']\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(fieldnames)\n",
    "    \n",
    "with open('NotFeature_sentences_Prod_Final_2018-07-09.csv','w') as csvfile2:\n",
    "    fieldnames=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE']\n",
    "    writer=csv.writer(csvfile2)\n",
    "    writer.writerow(fieldnames)\n",
    "\n",
    "feature_sentences = pd.read_csv('../product_feature_sentences/Feature_sentences_Prod_Active_2018-07-09.csv')\n",
    "sentences = 0\n",
    "pattern_match = 0\n",
    "no_pattern_match = 0\n",
    "\n",
    "def pos_pattern_search(text, grammar):\n",
    "    # tokenize, POS-tag, and chunk using regular expressions\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    tagged_sents = nltk.pos_tag_sents(nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(text))\n",
    "    all_chunks = list(itertools.chain.from_iterable(nltk.chunk.tree2conlltags(chunker.parse(tagged_sent))\n",
    "                                                    for tagged_sent in tagged_sents))\n",
    "    # join constituent chunk words into a single chunked phrase\n",
    "    candidates = [' '.join(word for word, pos, chunk in group).lower()\n",
    "                  #for key, group in itertools.groupby(all_chunks, lambda (word,pos,chunk): chunk != 'O') if key]\n",
    "                  #Python3:\n",
    "                  for key, group in itertools.groupby(all_chunks, lambda word__pos__chunk: word__pos__chunk[2] != 'O') if key]\n",
    "    return [cand for cand in candidates]\n",
    "\n",
    "for index, row in feature_sentences.iterrows():\n",
    "    sentences += 1\n",
    "    if type(row['SENTENCE']) is str:\n",
    "        if (len(pos_pattern_search(row['SENTENCE'], 'KT: {(<.+> <.+> <.+>)}')) > 0):\n",
    "            if (len(pos_pattern_search(row['SENTENCE'], 'KT: {(<JJ> <NN|NS> <.*>*)+}')) > 0\n",
    "            or len(pos_pattern_search(row['SENTENCE'], 'KT: {(<RB|RBR|RBS> <JJ> <C.*|D.*|E.*|I.*|J.*|l.*|NNP|P.*|R.*|T.*|U.*|V.*|W.*>)}')) > 0\n",
    "            or len(pos_pattern_search(row['SENTENCE'], 'KT: {(<JJ> <JJ> <C.*|D.*|E.*|I.*|J.*|l.*|NNP|P.*|R.*|T.*|U.*|V.*|W.*>)}')) > 0\n",
    "            or len(pos_pattern_search(row['SENTENCE'], 'KT: {(<NN|NNS> <JJ> <C.*|D.*|E.*|I.*|J.*|l.*|NNP|P.*|R.*|T.*|U.*|V.*|W.*>)}')) > 0\n",
    "            or len(pos_pattern_search(row['SENTENCE'], 'KT: {(<RB|RBR|RBS> <VB|VBN|VBD|VBG> <.*>)}')) > 0 ):\n",
    "                pattern_match += 1\n",
    "                #print(row['SENTENCE'])\n",
    "                #print(nltk.pos_tag(word_tokenize(row['SENTENCE']))) \n",
    "                feature_sentences_final = pd.DataFrame(columns=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE'])\n",
    "                feature_sentences_final.loc[0,'TESTIMONIAL_ID'] = row['TESTIMONIAL_ID']\n",
    "                feature_sentences_final.loc[0,'SENTENCE_ID'] = row['SENTENCE_ID']\n",
    "                feature_sentences_final.loc[0,'SENTENCE'] = row['SENTENCE']\n",
    "                feature_sentences_final.to_csv(\"Feature_sentences_Prod_Final_2018-07-09.csv\",mode='a', header=False, index=False)\n",
    "\n",
    "            else:\n",
    "                no_pattern_match +=1\n",
    "                not_feature_sentences_final = pd.DataFrame(columns=['TESTIMONIAL_ID','SENTENCE_ID','SENTENCE'])\n",
    "                not_feature_sentences_final.loc[0,'TESTIMONIAL_ID'] = row['TESTIMONIAL_ID']\n",
    "                not_feature_sentences_final.loc[0,'SENTENCE_ID'] = row['SENTENCE_ID']\n",
    "                not_feature_sentences_final.loc[0,'SENTENCE'] = row['SENTENCE']\n",
    "                not_feature_sentences_final.to_csv(\"NotFeature_sentences_Prod_Final_2018-07-09.csv\",mode='a', header=False, index=False)\n",
    "        else:\n",
    "            no_pattern_match +=1\n",
    "            #print(row['SENTENCE'])\n",
    "            #print(nltk.pos_tag(word_tokenize(row['SENTENCE']))) \n",
    "                \n",
    "print(\"Sentences:\", sentences, \"Pattern Match:\", pattern_match, \"No Pattern Match:\", no_pattern_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070247, 3)\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Sentence extraction validation\n",
    "path =r'..' # use your path\n",
    "allFiles = glob.glob(path + \"/data/RR_Pared_All_Active_SBD_2018-07-09_*.csv\")\n",
    "all_reviews = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "all_reviews = pd.concat(list_)\n",
    "\n",
    "print(all_reviews.shape)\n",
    "\n",
    "validation_sample = all_reviews.sample(n=1000)\n",
    "print(validation_sample.shape)\n",
    "validation_sample.to_csv(\"Validation_sentences_Prod_Active_2018-07-09.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERESTING\n",
      "0    804\n",
      "1    196\n",
      "dtype: int64\n",
      "(146018, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load labeled data set\n",
    "validated_sentences = pd.read_csv('Validation_sentences_Prod_Active_2018-07-09_Labeled_1K.csv', encoding='utf-8')\n",
    "# Distribution by Sentiment Class\n",
    "print(validated_sentences.groupby('INTERESTING').size())\n",
    "\n",
    "# Load pattern match final dataset\n",
    "pattern_match_final = pd.read_csv('Feature_sentences_Prod_Final_2018-07-09.csv', encoding='utf-8')\n",
    "print(pattern_match_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24378109452736318\n",
      "0.13643392600025975\n",
      "23.401682738908548\n"
     ]
    }
   ],
   "source": [
    "# Have to estimate false positives:\n",
    "#  assuming ratio in pattern_match_final to total is same as ratio of validation set\n",
    "positive_ratio_from_validation_set = (196/804) # \n",
    "print(positive_ratio_from_validation_set)\n",
    "positive_ratio_from_proccessing = (pattern_match_final.shape[0]/1070247)\n",
    "print(positive_ratio_from_proccessing)\n",
    "est_false_positives = 218 * (positive_ratio_from_validation_set - positive_ratio_from_proccessing)\n",
    "print(est_false_positives)\n",
    "#print(pattern_match_final.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Items: 196 True Positives: 29 False Negatives: 167\n",
      "  Estimated Precision= 0.5534173424256724\n",
      "  Recall= 0.14795918367346939\n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "false_negatives = 0\n",
    "selected_items = 0\n",
    "\n",
    "\n",
    "for index, row in validated_sentences.iterrows():\n",
    "    if row['INTERESTING'] == 1:\n",
    "        selected_items += 1\n",
    "        if pattern_match_final[(pattern_match_final['TESTIMONIAL_ID'] == row['TESTIMONIAL_ID']) \\\n",
    "                              & (pattern_match_final['SENTENCE_ID'] == row['SENTENCE_ID'])].empty:\n",
    "            false_negatives += 1\n",
    "        else:\n",
    "            true_positives += 1\n",
    "            \n",
    "            \n",
    "print(\"Selected Items:\", selected_items, \"True Positives:\", true_positives, \"False Negatives:\", false_negatives)\n",
    "print(\"  Estimated Precision=\", (true_positives/(true_positives+est_false_positives)))\n",
    "print(\"  Recall=\", (true_positives/(true_positives+false_negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
